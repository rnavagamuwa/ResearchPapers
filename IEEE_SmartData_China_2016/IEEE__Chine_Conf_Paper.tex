\documentclass[conference]{IEEEtran}  % Comment this line out
                                                          % if you need 
\usepackage{graphicx}
\usepackage{algorithm}% http://ctan.org/pkg/algorithm
\usepackage{algpseudocode}% http://ctan.org/pkg/algorithmicx
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{authblk}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{subfig}
\usepackage{float}
\usepackage{array}
\usepackage{amsmath}
\usepackage{csquotes}
\usepackage{multirow}

\makeatletter
\newcommand*{\rom}[1]{\expandafter\@slowromancap\romannumeral #1@}
\makeatother

\title{\LARGE \bf
Shapelets and Parallel Coordinates Based Automated Query Generation for Complex Event Processing
}

\author{R.N. Navagamuwa}
\author{K.J.P.G. Perera}
\author{M.R.M.J. Sally}
\author{L.A.V.N. Prashan}
\author{H.M.N. Dilum Bandara}
\affil[]{Department of Computer Science and Engineering\protect\\ University Of Moratuwa\protect\\ Katubedda, Sri Lanka \authorcr Email: {\tt (randika.12, pravinda.12, jaward.12, prashan.12, dilumb)@cse.mrt.ac.lk} \vspace{-2ex}} 

\begin{document}
\graphicspath{ {images/} }


\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Automating the query generation for Complex Event Processing (CEP) has marked its own importance in allowing users to obtain useful insights from data. Existing techniques are both computationally expensive and require extensive domain-specific human interaction. In addressing these issues, we propose a technique that combines both parallel coordinates and shapelets. First each instance of the multivariate data is represented as a line on a set of parallel coordinates. Then a shapelet-learner algorithm is applied to those lines to extract the relevant shapelets. Afterwards, the identified shapelets are ranked based on their information gain. Next, the shapelets with similar information gain are divided into groups by a shapelet-merger algorithm. The best group for each event is then identified based on the event distribution of the dataset. Then the best group is used to generate the query to detect the complex events. The proposed technique can be applied to both multivariate and multivariate time-series data, and it is computationally and memory efficient. It enables users to focus only on the shapelets with relevant information gains. We demonstrate the utility of the proposed technique using a set of real-world datasets.

\end{abstract}

\begin{IEEEkeywords} 
Complex Event Processing, Multivariate Time Series, Parallel Coordinates, Shapelets
\end{IEEEkeywords}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Automating query generation in large, multivariate datasets are useful in many applicationu domains. For example, Complex Event Processing (CEP) \cite{IEEEexample:CEP} combines data from multiple, streaming sources to identify meaningful events or patterns in real time. While the detection of relevant events and patterns may give insight about opportunities and threats related to the data being monitored (e.g., set of sensor readings and credit card transactions), significant domain knowledge is required to write effective CEP queries. Manual analysis of data streams is not only tedious and error prone, but also important events are likely to be missed due to the limited domain knowledge of the query writer. A promising alternative is to automate the CEP query generation by automatically extracting/mining interesting patterns from the past data \cite{IEEEexample:autoCEP,IEEEexample:TowardsAutomated,IEEEexample:LearningFromThePast}.

Time-series pattern mining and classification techniques are extensively studied in the literature. Dynamic Time Warping (DTW) \cite{IEEEexample:DTW} is one such technique used to measure the similarity between two time series based on a distance measure. However, the computational complexity of DTW grows exponentially with large and multiple time series limiting its usages. Moreover, the accuracy of the results depends on the chosen sliding window, which is nontrivial to estimate \cite{IEEEexample:autoCEP}. A shapelet \cite{IEEEexample:TimeSeriesShapelets} is a time series subsequence that is identified as being representative of class membership; hence, useful in time-series classification. AutoCEP \cite{IEEEexample:autoCEP} proposed a shapelet-based technique to automate the CEP query generation for univariate time series. This itself is a major limitation as the practical presence of univariate time series is limited in CEP. Moreover, AutoCEP generates queries for each and every instance of the detected event, requiring the CEP engine to concurrently process multiple queries. This unnecessarily increases the computational and memory requirements of the CEP engine and consequently degrades its performance. One trivial optimization is to use the assistance of a domain-expert to aggregate the queries and attempt to write one or few queries. Ultra-fast shapelets \cite{IEEEexample:UltraFast} are proposed for multivariate time-series classification. Ultra-fast shapelets calculates a vectorized representation of respective attributes of the dataset. Then a random forest is trained to identify the shapelets with respect to the total dataset. The leaves of the random forest are considered to be the symbols. The number of occurrences of a symbol in the raw data is counted and these symbol histograms are used for the final classification using random forests. While this technique is effective in classification, it cannot be used to generate CEP queries, as the generated random forest does not support backtracking and obtaining any relevant information as to what data lead to the classification of the event \cite{IEEEexample:UltraFast}. Rare itemset pattern mining (AprioriRare) \cite{IEEEexample:RareItemSet} is another technique. This technique cannot be used to detect events that occur within a short period of time. Moreover, most related work focus only on domain-specific datasets limiting the usability across diverse datasets and applications \cite{IEEEexample:UserOriented,IEEEexample:WebBased}.

We propose a technique that represents the given multivariate dataset as a set of parallel coordinates, and then extract shapelets out of those coordinates to auto generate CEP queries. Even a time series can be mapped to a set of parallel coordinates, by representing each time instance as a separate line. Extracted shapelets are sorted according to the information gains and then divided into a several groups. Out of the all groups, best group for each event is identified. Then the most important shapelets in the identified groups are used to generate one CEP query per group. This enables one to generate CEP queries for commonalities, anomalies, as well as time-series breakpoints in a given multivariate time-series dataset without having any domain knowledge. Users can focus on groups with high or low information gain depending on the application. Moreover, shapelets identify most relevant attributes in a dataset for a particular event, enabling us to write more efficient CEP queries and only one query per event (unless the same event is triggered by unrelated attribute combinations). Using a set of real-world datasets, we demonstrate that the proposed technique can be applied effectively to auto generate CEP queries for common and abnormal events while identifying the relevant features and event occurrence timeframe. Moreover, the proposed technique has a relatively low computational and memory requirements compared to prior work.

Rest of the paper is organized as follows. Section II introduces shapelets, parallel coordinates, and problem formulation. Section III presents the proposed technique and Section IV explains implementation details. Performance analysis is presented in Section V. Concluding remarks and future work are discussed in Section VI.

\section{Preliminaries}
We first define relevant terms and then define shapelets and parallel coordinates as applicable to the domain of CEP query generation. The research problem is then formulated.
\subsection{Definitions}
\noindent
\textbf{\textit{Time-Series}} --- A time-series $T = t\textsubscript{1},..., t_m$ is an ordered set of \textit{m} real-valued variables.
\smallskip\\
\textbf{\textit{Multivariate Time-Series}} --- A multivariate time-series $T = t\textsubscript{1}, . . . , t_m$ is a sequence of \textit{m} vectors, where $t_i = (t_{i,1}, . . . , t_{i,s})$ $\epsilon$ $\mathbb{R}\textsuperscript{\(s\)}$ with \textit{s} attributes/variables.
\smallskip\\
\textbf{\textit{Sub-sequence ($S^t_p$)}} --- Given a time-series $T$, a subsequence $S^t_p$ of $T$ is a sampling of length $l$ \(\leq\) $m$ of contiguous positions from $T$ starting at time $p$, i.e., $S^t_p = t_p, t_{p+1}...,t_{p+l-1}$, for 1 \(\leq p \leq m - l + 1\).
\smallskip\\
\textbf{\textit{Set of All Sub-sequences ($ST_l$)}} --- Set of all possible sub-sequences $S^t_p$ that can be extracted by sliding a window of length $l$ across $T$ is $ST_l$ = \{all $S^t_p$ of $T$, for 1 \(\leq p \leq m - l + 1\)\}.

\enlargeeup
\noindent
\textbf{\textit{Sub-sequence Distance}} --- Given $T$ and $S^t_p$ \(SubsequenceDist(T,S^t_p)\) is the minimum distance between $p$ contiguous positions obtained by sliding $S^t_p$ across $T$. We use Euclidean distance as the distance function.
\smallskip\\
\textbf{\textit{Entropy}} --- Consider a time series dataset \textbf{D} consisting of two classes, $A$ and $B$. Let proportions of objects belonging to class $A$ and $B$ be $p(A)$ and $p(B)$, respectively. Then the entropy of \textbf{D} is:
\begin{equation}
 I(\textbf{D}) = -p(A)log(p(A)) - p(B)log(p(B))
 \label{eq:id}
\end{equation}
\noindent
\textbf{\textit{Information Gain (Gain)}} --- Given a certain split strategy $sp$ which divides \textbf{D} into two subsets \textbf{D\textsubscript{1}} and \textbf{D\textsubscript{2}}, let the entropy before and after splitting be $I(\textbf{D})$ and $\hat{I}(\textbf{D})$, respectively. Then the information gain for split $sp$ is:
\begin{equation}
\begin{split}
Gain(\textit{sp}) = I(\textbf{D}) - \hat{I}(\textbf{D})\\
Gain(\textit{sp}) = I(\textbf{D}) - (p(\textbf{D\textsubscript{1}})(I\textbf{D\textsubscript{1}})+p(\textbf{D\textsubscript{2}})I(\textbf{D\textsubscript{2}}))
\end{split}
\label{eq:gain}
\end{equation}

\enlargeeup
\noindent
\textbf{\textit{Optimal Split Point (OSP)}} --- Consider a time-series dataset \textbf{D} with two classes $A$ and $B$. For a given $S^t_p$, we choose some distance threshold $d_{th}$ and split \textbf{D} into \textbf{D}\textsubscript{1} and \textbf{D}\textsubscript{2}, s.t. for every time series object $T_{1,i}$ in \textbf{D}\textsubscript{1}, $SubsequenceDist(T_{1,i}, S^t_p) \leq d_{th}$ and for every $T_{2,i}$ in \textbf{D}\textsubscript{2}, $SubsequenceDist(T_{2,i}, S^t_p) \geq d_{th}$. An Optimal Split Point (OSP) is a distance threshold that $Gain(S^t_p,d_{OSP(D,S^t_p)}) \geq Gain(S^t_p,d'_{th})$ for any other distance threshold $d'_{th}$.

\subsection{Shapelets}
\textit{Shapelets} can be defined as time-series sub-sequences as seen in Fig.~\ref{fig:shapelets}. 
%A dataset can be converted to two dimensional representation of time series \cite{IEEEexample:TimeSeriesShapelets}. This representation can be used for time-series classification based on the shapes of the data within the time series. For example, many subsequences can be identified on a time series , and those subsequences are called shapelets. 
Shapelets can be of varying lengths, and many sub-sequences can be extracted by sliding a window of given length $l$. In shapelet-based classification, the objective is to identify a shapelet that is in some sense maximally representative of a class.
%and all possible subsequences can be extracted using sliding window as illustrated in Fig. 2.
%\smallskip\\
%\begin{figure}
%\centering
%\begin{minipage}{9cm}
%\parbox{9cm}{
%\includegraphics[width=9cm,height=3cm]{shapelet1.png}
%\caption{Time-series shapelets.}
%\label{fig:2figsA}}
%\qquad
%\parbox{9cm}{
%\includegraphics[width=9cm,height=4cm]{shapelet2.png}
%\caption{Shapelets with sliding window.}
%\label{fig:2figsB}}
%\end{minipage}
%\end{figure}

\begin{figure}
\includegraphics[width=9cm,height=3cm]{shapelet1.png}
\caption{Time-series shapelets.}
\label{fig:shapelets}
\end{figure}

\subsection{Parallel Coordinates}
Parallel coordinates are widely used to visualize multivariate data \cite{IEEEexample:ParallelCoordinates}. Fig.~\ref{fig:parallcor}. Fig.~\ref{fig:parallcor} illustrates the parallel coordinates representation of the room occupancy dataset obtained from the UCI Machine Learning repository \cite{IEEEexample:Ocupancy}, which consists of six attributes. Dataset with $n$ dimensions (i.e., attributes) is mapped to a set of points on $n$ parallel lines, where each line represents an instance of data. These points are then connected using a line. A separate line is drawn for each instance of data (i.e., each row). For example, in Fig.~\ref{fig:parallcor} part of the dataset selected based on the "Light" attribute is shown in black, and rest of the dataset is visualized in grey. When scaling these coordinate systems, it is recommended to use normalized data to prevent bias to certain dimensions.

\begin{figure}
\includegraphics[width=9cm,height=3.5cm]{occupancy_d3.png}
\caption{Parallel coordinates representation of Occupancy Detection dataset \cite{IEEEexample:Ocupancy}.}
\label{fig:parallcor}
\squeezeup
\end{figure}


\subsection{Problem Statement} 
In contrast to relational database systems that issue dynamic queries on stored and indexed data, CEP filters incoming streams of data through pre-written queries to detect events of interest. Hence, relevant queries need to be provided to the CEP engine a priori. We address the problem of needing domain knowledge to write a meaningful CEP queries through automation. Though a couple of related work attempt to automate CEP query generation, they support only univariate time series data \cite{IEEEexample:autoCEP}.

We propose a solution which can be used to generate CEP queries for multivariate time series without requiring expert domain knowledge. In proposing the solution we assume that each instance in the obtained dataset is annotated according to the respective event. Our goal is to construct a filter query per event, which contains the most relevant attributes, their range of values, and the event detection time frame. An example CEP filter query may look like the following:

\begin{equation}
\begin{split}
\textbf{SELECT }\ \{*\} \\ \textbf{WHERE}\ \{attr_1\geq a\ and \ attr_2<b\} \\ \textbf{WITHIN}\ \{t_1\leq time\leq t_2\}
\label{eq:query}
\end{split}
\end{equation}

\begin{figure}
\includegraphics[width=0.5\textwidth]{High_level_architecture.png}
\caption{High-level architecture of the proposed solution.}
\label{fig:archi}
\end{figure}

\section{Proposed Technique}
To auto generate queries for Complex Event Processors, we propose the modularized architecture illustrated in Fig.~\ref{fig:archi}. The four main modules perform the following tasks:

\textbf{Data Processor} --- Converts the input dataset (e.g., time series data in .txt, .xml, or .csv format) into a generic format used by rest of the modules. We assume that each instance in the given dataset corresponds to an occurrence of a specific event, i.e., each data instance is classified/labeled with the corresponding event. The module then counts the number of events of each type, and their proportions with respect to the total number of events in the entire dataset.

\textbf{Shapelet Generator}	--- This is the core module of the system which uses pattern mining. This module identifies the most appropriate shapelets to represent each event. First, the multivariate time series dataset is mapped to a set of parallel coordinates. Fig.~\ref{fig:tsdata} is an exemplary representation of a multivariate time series with six attributes and six time instances converted to parallel coordinates. Then all the shapelets are extracted from the parallel coordinates while varying the length $l$ of the sliding window. Though the shape of the extracted shapelets depend on the order of the attributes, final outcome of the solution is independent of the order. Length of an identified shapelet is bounded by number of attributes $m$ in the time series (i.e., $1 \leq l \leq m$). Therefore, our technique produces a much lower number of shaplets compared to prior work, where $m$ can be as large as the length of the time series. Moreover, it is not required to apply heuristics or expert knowledge to determine the optimum minimum and maximum length of shapelets. Therefore, our \textit{Shapelet Learner Algorithm} is both computationally and memory efficient.

Once all shapelets are extracted, the next step is to identify a subset of the shapelets that are representative of patterns in the parallel coordinates. For this, we use information gain to quantify the extent to which a selected shapelet is similar to a given line on parallel coordinates. For example, Fig.~\ref{fig:tsshapes} shows two shaplets, one with attributes 1 and 2 (shapelet $S_1$) and another with attributes 1, 2, and 3 (shapelet $S_2$). We slide both $S_1$ and $S_2$ across the line/row with $t$ = 5000, and find the minimum distance between the shapelet and line. For example, $S_1$ has a relatively lower distance between the attributes 1-2 and 3-4, whereas $S_2$ has a relatively lower distance between attributes 1-3 and 4-6. This is estimated using the \textit{SubsequenceDist()} function defined in Sec. 2.1. The same process is applied to all other time instances and shapelets. This results in a matrix of minimum distance values for each (shapelet, time instance) pair. We then find the Optimal Splitting Point (OSP) \cite{IEEEexample:TimeSeriesShapelets} for each row of minimum distance values, to find the maximum information gain for each shapelet. The shapelets are then ranked based on the descending order of its information gain. We then use \textit{Shapelet Merger Algorithm} to group shapelets within the ranked list with respect to their information gain. Because the shapelets with similar information gains produce similar insights, groups created using \textit{Shapelet Merger Algorithm} allows us to cluster the similar informative shapelets together. Finally, \textit{Important Shapelet Extraction Algorithm} is used to identify the most suitable shapelets to represent each event type, which would result in an output similar to Fig.~\ref{fig:tswin}.

\textbf{Visual Representation} --- This module visualizes generated shapelets, optionally enabling users to select what shapelets to choose for query writing. While the system can auto generate queries without any user suggestions, this module facilitates and accepts user approval allowing the user to select the shapelets that user is interested in. As seen in Fig.~\ref{fig:tswin} user may also select subset of the attributes and their range of values that he/she expects to use in the generated queries. Such user intervention reduces false positives and improves performance of the CEP engine, as not every identified event may be of practical importance.

\begin{figure}
\includegraphics[width=9cm,height=5cm]{multivariateTime.png}
\caption{Multivariate time series mapped as parallel coordinates.}
\label{fig:tsdata}
\end{figure}

\begin{figure}
\includegraphics[width=0.5\textwidth]{movingWindow.png}
\caption{Shapelets slide accross the time series.}
\label{fig:tsshapes}
\end{figure}

\begin{figure}
\includegraphics[width=0.5\textwidth]{demo.png}
\caption{Shapelets that are representative of event.}
\label{fig:tswin}
\end{figure}

\textbf{Query Generator} --- Given the chosen shapelets this module auto generates CEP queries based on the input provided by the hint generator module and incorporating any user provided hints. Here we generate one query per each event with the relevant query parameters generated by the system, or set of attributes and ranges approved by the user. The module identifies the most relevant attributes and their value ranges to be used in constructing the query along with the optimal time periods within which each event occurs. Optimal time periods are identified by analyzing the event distribution of the actual dataset and choosing the longest event detection time period with respect to each occurrence of event. Using these data, the module generates filter queries (similar to Eq. 3) for each and every event of the given dataset.

\section{Implementation}
%Few and recent efforts that touched about Shapelets are discussed in \cite{IEEEexample:TimeSeriesShapelets,IEEEexample:ExtractingShapelets,IEEEexample:autoCEP}. 
In this paper we introduce a new approach to define shapelets using parallel coordinates as an object with four attributes ${s = (g,i,a,c)}$. $g$ is the information gain, which measures the similarity between shapelet and time series. $i$ is the time series identifier, which is the row number of the line on parallel coordinates (see Fig.~\ref{fig:tsdata}). $a$ is the starting column/attribute number. We store the normalized values of the attributes which belong to the particular shapelet in $c$. We also keep track of the original values $c$, as those are later required to generate CEP queries.

We first transform the multivariate time series dataset into parallel coordinates as seen in Fig.~\ref{fig:parallcor}. Our method builds upon two main phases which are illustrated in Fig.~\ref{fig:hintgen}. Next, implementation of each phase is discussed in detail.
%We then extract all possible shapelets from the parallel coordinates representation. , and then identify important shapelets for further processing


\subsection{Phase one: Shapelet Learner}
The \textit{Shapelet Learner} extracts all the shapelets from the obtained parallel coordinates. We set the default minimum length ($l_{min}$) of a shapelet as two, while the maximum ($l_{max}$) is set to the number of attributes $m$ (i.e., $2 \leq l \leq m$). However, a user may override these values. Afterwards, Algorithm 1 of the Shapelet Generator module extracts all possible shapelets while varying the shapelet length. First, the shapelet list is initialized to store the extracted shapelets (line 2). Then shapelets are extracted by going through each row $r$ in the Dataset \textbf{D}. The outer loop increments the length of a shapelet $l$ up to $l_{max}$, while the inner loop increments $start$ to scans through each $r$. The inner-most loop (line 13 -1 ) extracts all attributes between $l_{min}$ to $l$ for a given staring point. Then we convert each shapelet’s content to standard normal using \textit{zNorm()} function to prevent any biases to specific attributes. Moreover, in line 19 we also store the raw values of shapelets, as they are later required while generating queries. 

We also calculate and save the information gain of each shapelets using \textit{infoGain()} function (line 20). First, the \textit{SubsequenceDist()} function is used to find the minimum distance between the row and the shapelet by sliding the shapelet across the row, one attribute at a time (see Fig. \ref{fig:tsshapes}). By repeating the function, the minimum distance per each row is found and saved in an array. Then by sequeuntially splitting the array we calculate the information gain using Eq. 2. Finally, for each shapelet we get the maximum information gain and the corresponding split point, which would be the Optimum Splitting Point of the array. In line 21, each shapelet and its metadata are then added to the \textit{shapelets} list, which is later returned by the algorithm.

\subsection{Phase Two - Shapelet Extraction}
All the extracted shapelets are first sorted according to their information gain. Then these shapelets are divide into a set of groups and then merged using Algorithm 2. Algorithm take the set of shapelets $S$ and number of shapelets per group ($group_{size}$) as the input. 
%$group_{size}$ is proportional to the total number of shapelets. 
$group_{size}$ is selected based on the cluster pruning technique in which we set the number of groups to the square root of the total number of identified shapelets. If desired, the user may also define the $group_{size}$. Then in line 12 to 15 the grouped shapelets are updated by adding their series ID (i.e., raw number), starting positions (i.e., starting attribute index), lengths (i.e., number of attributes), and class value (i.e., event type). Finally, the algorithm return all the merged shapelets (line 25).

\begin{figure}
\includegraphics[width=0.5\textwidth]{Architecture.png}
\caption{Architecture of the Shapelet Generator module.}
\label{fig:hintgen}
\end{figure}

\begin{figure}
\includegraphics[width=0.5\textwidth]{algo1.png}\squeezeup\squeezeup\squeezeup
\end{figure}
\begin{figure}
\includegraphics[width=0.5\textwidth]{algo2.png}\squeezeup\squeezeup\squeezeup
\end{figure}

%Each shapelet of the $mergedShapelets$ array will have three additional variables. They are as follows
%\begin{itemize}
%\item Class value
%\item Starting position
%\item Series ID
%\end{itemize}

\textit{Important Shapelet Finder} algorithm (Algorithm 3) takes in three parameters, namely merged shapelets, classified/labelled dataset. and class values (i.e., event types). Line 2 and 3 initialize two lists named \textit{shapletArr} and \textit{classValueProb}, which would respectively contain important shapelets and probabilities for class values within the total dataset. Then for each class value, a \textit{set} data structure is created named \textit{shapeletBucket}. \textit{findProb()} function calculates the probability of the relevant class values within the dataset, and then put that to \textit{shapeletBucket} (line 8 to 10). As the next step, (in line 12 to 17) each merged shapelet is included into a relevant \textit{shapeletBucket}, based on the most probable class values for each group of shapelets. This is achieved using \textit{maxProbClassVal()} function. Next, Algorithm 3 finds the absolute differences between the probabilities of actual events of the dataset and groups of shapelets. This is calculated using the \textit{getMinDifShape()} function (line 28). Because the chosen group of shapelets per each event comprises of the minimum difference with respect to the actual event distribution in the dataset, it enables us to choose the most representative groups of shapelets per each event. Finally, the extracted group of shapelets are added to the \textit{shapeletArr} (line 29).

Regardless of the CEP query language, two blocks are needed to generate a meaningful CEP query for an event (see Eq. 3). First, the time frame (or window) of the rule need to be identified from the extracted shapelets. This is specified using the \textit{within} construct. Second, the conditions that need to be met on the captured sequence of events is defined using the \textit{where} construct. Once the relevant parameters and constructs are known, we use the technique proposed in \cite{IEEEexample:autoCEP} to automatically generate the queries.
%\vspace{0.1cm}
%\begin{equation}
%\textbf{within}[window] \textbf{where}[conditions]
%\label{eq:withinWhere}
%\end{equation}
 The \textit{conditions} are extracted using the selected attributes and their respective range of the important shapelets. If user wants to get a CEP rule to identify multiple events, in addition to above two blocks, \textit{filter} block should be added as follows:
\begin{equation}
\textbf{within}[window] \{relevent-events\} \textbf{where}[conditions]
\label{eq:releventEvents}
\end{equation}

\begin{figure}
\includegraphics[width=0.5\textwidth]{algo3.png}\squeezeup\squeezeup\squeezeup
\end{figure}

\section{Performance Analysis}
We use two multivariate time series datasets from UCI machine learning repository \cite{IEEEexample:Ocupancy,IEEEexample:EEG} to demonstrate that our technique can automate CEP query generation for different types of domains. We quantify the accuracy of the generated CEP queries using recall, precision, false positives, and false negatives. 

\subsection{Occupancy Dataset} 
“Occupancy Detection” dataset \cite{IEEEexample:Ocupancy} is a multivariate time-series dataset of which measure the occupancy factor of an office room with respect to light, temperature, humidity, and CO2 measurements. It consists of 8,143 instances out of which 6,414 (78\%) instances are labeled as not occupied (\textit{occupancy} = 0) while the remaining 1,729 (21\%) instances are labeled as occupied (\textit{occupancy} = 1). Our objective is to auto generate queries to detect both the occupied and not occupied events.

This dataset results in 9,344 shapelets, and then the most appropriate shapelets are filtered out and used for the query generation process. Fig.~\ref{fig:occupancyEvent1} and Fig.~\ref{fig:occupancyEvent2} illustrate the most appropriate shapelets to detect not occupied and occupied events. Most appropriate shapelets of Fig.~\ref{fig:occupancyEvent1} are within attributes 1 and 3 (i.e., humidity and CO2). As seen on Fig.~\ref{fig:occupancyEvent2} for the occupied event CO2 and humidity ratio attributes are more relevant. The longest time window for not occupied events was between 17:32:00 - 22:23:00 on 2015/02/08. Whereas for the occupied events it was 14:49:00 - 18:40:00 on 2015/02/09. Based on these time gaps we set the event detection time frame. These attributes, their range of values, and the optimal event detection time frames are then used to generate queries.

\begin{figure}
\includegraphics[width=0.5\textwidth]{Occupancy_event1.png}
\caption{Shapelets corrosponding to not occupied events.}
\label{fig:occupancyEvent1}
\squeezeup\squeezeup
\end{figure}

\begin{figure}
\includegraphics[width=0.5\textwidth]{Occupancy_event2.png}
\caption{Shapelets corrosponding to occupied events}
\label{fig:occupancyEvent2}
\squeezeup\squeezeup
\end{figure}


Table \rom{1} summarizes the accuracy of detected events based on the auto generated queries. It can be seen that the generate CEP query is able to detect all the occupied events, it missed a few not occupied events (1.7\% of total dataset). However, false positives for occupied events were relatively high (18.4\%). Overall recall, precision, false positive, and false negative values are acceptable for both the occupied and not occupied events, indicating the usefulness of auto generate CEP queries. 

\begin{table}
\caption{Occupancy dataset event detection results.}
\begin{tabular}{ |l|l|l| }
\hline
\textbf{Event} & \textbf{Metric} & \multicolumn{1}{|r|}{\textbf{Value}}\\
\hline
\multirow{6}{*}{Not occupied} & No of events in dataset & \multicolumn{1}{|r|}{291}\\
    & No of events detected using CEP query & \multicolumn{1}{|r|}{286}\\ 
    & Recall & \multicolumn{1}{|r|}{98.28\%}\\
    & Precision & \multicolumn{1}{|r|}{100.00\%}\\
    & False positives & \multicolumn{1}{|r|}{0}\\
    & False negatives & \multicolumn{1}{|r|}{5 (1.72\%)}\\
\hline
\multirow{6}{*}{Occupied} & No of events in dataset & \multicolumn{1}{|r|}{196}\\
    & No of events detected using CEP query & \multicolumn{1}{|r|}{196}\\
    & Recall & \multicolumn{1}{|r|}{100.00\%}\\
    & Precision & \multicolumn{1}{|r|}{84.48\%}\\
    & False positives & \multicolumn{1}{|r|}{36 (18.37}\\
    & False negatives & \multicolumn{1}{|r|}{0}\\
\hline
\end{tabular}
\squeezeup\squeezeup
\end{table}


\subsection{EEG Eye State Dataset}
Next, we used electroencephalogram (EEG) dataset related to opening and closing of eyes \cite{IEEEexample:EEG}. The eye state was detected via a camera during the EEG measurement, and later used to annotate the EEG time series by analysing the video frames. Eye-open state is indicated using binarry 0 while the eye-closed state is indicated using 1. Fig.~\ref{fig:EEGEvent1} and ~\ref{fig:EEGevent2} correspond to the most appropriate shapelets to detect event 0 and 1 respectively. Most appropriate shapelets for eye-open state are within attributes 8-13 (Fig.~\ref{fig:EEGEvent1}). As seen on Fig.~\ref{fig:EEGEvent1} attributes 4-5, 6-7, and 8-9 are more relevant for eye-closed event. The longest time window for eye-open state was between time stamps 128,349s to 204,516s, while for the eye-closed events it was 14,976s to 128,232s. We generate queries based on these three shapelets and event detection time frames. As there are three shapelets the \textbf{where} clause in Eq. 3 is of the form (\textit{Attr 4's range} AND \textit{Attr 5's range}) OR (\textit{Attr 6's range} AND \textit{Attr 7's range}) OR (\textit{Attr 8's range} AND \textit{Attr 9's range}).

Table \rom{2} summarizes the accuracy of detected events based on the auto generated queries. For this dataset zero false positives are observed for both eye-open and eye-closed events. False negatively are also very low for both events (2.7\% and 0.1\%, respectively). Both the precision and recall are also close to 100\%, indicating that results queries are able to detect relevant events with good accuracy.

\begin{figure}[h!]
\includegraphics[width=0.5\textwidth]{EEG_event1.png}
\caption{Shapelets corrosponding to EEG eye-open state.}
\label{fig:EEGEvent1}
\end{figure}

\begin{figure}[h!]
\includegraphics[width=0.5\textwidth]{EEG_event2.png}
\caption{Shapelets corrosponding to EEG eye-closed state.}
\label{fig:EEGevent2}
\end{figure}

%Table \rom{2} displays a summarized representation of the obtained accuracy values of the generated queries for eye open and close events of the EEG Eye state dataset.

\begin{table}
\caption{EEG Eye State dataset event detection results.}
\begin{tabular}{ |l|l|l| }
\hline
\textbf{Event} & \textbf{Metric} & \multicolumn{1}{|r|}{\textbf{Value}}\\
\hline
\multirow{6}{*}{Eye-open} & No of events in dataset & \multicolumn{1}{|r|}{652}\\
    & No of events detected using CEP query & \multicolumn{1}{|r|}{635}\\ 
    & Recall & \multicolumn{1}{|r|}{97.39\%}\\
    & Precision & \multicolumn{1}{|r|}{100.00\%}\\
    & False positives & \multicolumn{1}{|r|}{0}\\
    & False negatives & \multicolumn{1}{|r|}{17 (2.67\%)}\\
\hline
\multirow{6}{*}{Eye-closed} & No of events in dataset & \multicolumn{1}{|r|}{69}\\
    & No of events detected using CEP query & \multicolumn{1}{|r|}{68}\\
    & Recall & \multicolumn{1}{|r|}{98.55\%}\\
    & Precision & \multicolumn{1}{|r|}{100.00\%}\\
    & False positives & \multicolumn{1}{|r|}{0}\\
    & False negatives & \multicolumn{1}{|r|}{1 (1.45\%)}\\
\hline
\end{tabular}
\squeezeup\squeezeup
\end{table}

\section{Summary and Future Work}
We proposed technique to automatically generate CEP queries based on multivariate time series data. The proposed technique first map the multivariate time series to a set of parallel coordinates. Then key patterns that are representative of the events are identified using time series shapelets. We also propose a technique to identify the most relevant shapeless per event, such that only a single CEP query will be generated per event. The proposed technique is both computationally and memory efficient compared to prior work, as the length of a shapelet is bounded by the number of attributes. Moreover, the performance of the CEP engine is also improved, as only one query will be generated per events. Furthermore, using two real datasets, we demonstrate that the resulting queries have good accuracy in detecting relevant events. In future we plan to further improve the accuracy and extend the proposed technique work with unlabeled time series datasets.

\nocite{*}
\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,IEEEexample}

\end{document}
